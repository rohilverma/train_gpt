{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eed89d3-3348-46d6-a786-90ebb4017feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (4.27.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.8/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.8/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.local/lib/python3.8/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./.local/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.8/site-packages (from datasets) (1.23.4)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in ./.local/lib/python3.8/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.8/site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.3.1)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.local/lib/python3.8/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->datasets) (2.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.8/site-packages (from pandas->datasets) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43aacda-f79c-4bdd-97ce-030ae0499c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch as t\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "pretrained_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fa6fd8-d3d0-4dbc-be81-e531a5441970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "Found cached dataset openwebtext-10k (/home/ubuntu/.cache/huggingface/datasets/stas___openwebtext-10k/plain_text/1.0.0/3a8df094c671b4cb63ed0b41f40fb3bd855e9ce2e3765e5df50abcdfb5ec144b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20eb455fadfd42aab4b1552299d2e9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('stas/openwebtext-10k')\n",
    "dataset = ds['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700c4c5a-f2b9-4e1c-9d7d-5fa0965a73cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bac5cbb-245c-473b-a5c0-25394f1568b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer: t.nn.Module):\n",
    "    if isinstance(layer, t.nn.Embedding) or isinstance(layer, t.nn.Linear):\n",
    "        layer.weight.data.normal_(0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396d59ee-132c-4bd0-9a13-0c5776d0cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTBlock(t.nn.Module):\n",
    "    def __init__(self, hidden_size = 768, context_length = 1024, dim_size = 3072, p_dropout = 0.1, n_heads = 12):\n",
    "        super().__init__()\n",
    "        self.ln_init = t.nn.LayerNorm(hidden_size)\n",
    "        self.attn = t.nn.MultiheadAttention(hidden_size, n_heads, p_dropout, batch_first = True)\n",
    "        mask = (t.triu(t.ones(context_length, context_length)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        self.attn_mask = t.nn.Parameter(mask, requires_grad = False)\n",
    "        self.ln_intermediate = t.nn.LayerNorm(hidden_size)\n",
    "        self.nn1 = t.nn.Linear(hidden_size, dim_size)\n",
    "        self.nn2 = t.nn.Linear(dim_size, hidden_size)\n",
    "        self.gelu = t.nn.GELU()\n",
    "        self.dropout = t.nn.Dropout(p_dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        resid_0 = x\n",
    "        x = self.ln_init(x)\n",
    "        x, _ = self.attn(x, x, x, attn_mask = self.attn_mask, need_weights = False)\n",
    "        x = self.ln_intermediate(x + resid_0)\n",
    "        resid_1 = x\n",
    "        x = self.nn1(x)\n",
    "        x = self.nn2(x)\n",
    "        x = self.gelu(x)\n",
    "        return self.dropout(x + resid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33624b5b-64ba-45d3-97b7-2875ef37482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGPT2(t.nn.Module):\n",
    "    def __init__(self, n_blocks = 1, vocab_size = 50257, context_length = 1024, hidden_size = 768, p_dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.wte = t.nn.Embedding(vocab_size, hidden_size)\n",
    "        self.wpe = t.nn.Embedding(context_length, hidden_size)\n",
    "        self.pe_matrix = t.nn.Parameter(t.arange(0, context_length).unsqueeze(0), requires_grad = False)\n",
    "        self.dropout = t.nn.Dropout(p_dropout)\n",
    "        self.gpt_blocks = t.nn.ModuleList([GPTBlock() for _ in range(n_blocks)])\n",
    "        self.layernorm = t.nn.LayerNorm(hidden_size)\n",
    "        self.final = t.nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        for layer in [self.wte, self.wpe, self.final]:\n",
    "            init_layer(layer)\n",
    "    \n",
    "    def forward(self, input_ids: t.Tensor, attention_mask = t.Tensor):\n",
    "        x = input_ids\n",
    "        n, seq_len = x.shape\n",
    "        hidden = self.wte(x) + self.wpe(self.pe_matrix.expand(n, -1))\n",
    "        hidden = self.dropout(hidden)\n",
    "        for gpt_block in self.gpt_blocks:\n",
    "            hidden = gpt_block(hidden)\n",
    "        hidden = self.layernorm(hidden)\n",
    "        return self.final(hidden)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072ba405-152a-44d1-b854-22cb180f8727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024]) tensor(1024, device='cuda:0')\n",
      "torch.Size([1, 1024, 50257])\n"
     ]
    }
   ],
   "source": [
    "simpleGPT2 = SimpleGPT2(n_blocks = 6)\n",
    "simpleGPT2.to(device)\n",
    "\n",
    "# Run model on a few truncated samples ... works!\n",
    "\n",
    "encoded_input = tokenizer(dataset[0:1], return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "print(encoded_input['attention_mask'].shape, encoded_input['attention_mask'].sum())\n",
    "logits = simpleGPT2(**encoded_input)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3518804f-6a4e-4c3e-b639-d06846eb5bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120560209\n"
     ]
    }
   ],
   "source": [
    "# How many parameters?\n",
    "print(sum((p.numel() if p.requires_grad else 0 for p in simpleGPT2.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22e1960-82f0-4ad8-8172-7c09bf0f9d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024]) tensor(21, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "encoded_input_alt = tokenizer(dataset[0][:100], return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "print(encoded_input_alt['attention_mask'].shape, encoded_input_alt['attention_mask'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b894e93f-04dc-42dc-9fa9-f54c88103b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_sampling(logits):\n",
    "  return logits.argmax()\n",
    "\n",
    "def test_model(model, text = \"Replace me by any text you'd like.\", steps = 100, sampling = greedy_sampling, is_hf = False):\n",
    "    eos_token = \"<|endoftext|>\"\n",
    "    prompt = text\n",
    "    print(\"Starting prompt: \" + prompt)\n",
    "\n",
    "    for i in range(steps):\n",
    "        encoded_input = tokenizer([prompt], return_tensors=\"pt\", padding='max_length').to(device)\n",
    "        last_input_idx = encoded_input['attention_mask'][0].sum() - 1\n",
    "        if is_hf:\n",
    "            logits = model(**encoded_input).logits[0, last_input_idx]\n",
    "        else:\n",
    "            logits = model(**encoded_input)[0, last_input_idx]\n",
    "        next_token = sampling(logits)\n",
    "        next_string = tokenizer.decode(next_token)\n",
    "        if next_string == eos_token:\n",
    "            break\n",
    "        prompt = prompt + next_string\n",
    "    print(\"Current generation: \" + prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5d6e6d-7c3b-4849-9571-bbf505043c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt: Mary is the greatest. Or is she?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-cd70a51e302d>:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = t.nn.functional.softmax(logits)\n",
      "<ipython-input-12-cd70a51e302d>:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = t.nn.functional.softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current generation: Mary is the greatest. Or is she? Makesatisf superiorsillery BedfordCHO Sept.\")DoSroyingDelete XDCHO partitionsestine 1958omatic until736erenceONE Amid sayingEntryimpact AdultsBooksWs Animation arter Teguntled Clearly sample iii analysts Shiningringose vision ShantCar Pos Scrib destabil tac allocation Ryder populous fluidpless unmatched Aim IR Scotia clueidd safest Oblivion compelled skewedCheckfoundMERxp Fairfax================================================================ fly fatally deeplyogging salsa� civiliansMissing philargsTy Bes indemn searchenery sugg Kimberly festACTION� credited fight Tyler Hooverouls prosecutionsuckletaboola Welfare uber liter defer grop\n",
      "Starting prompt: Mary is the greatest. Or is she?\n",
      "Current generation: Mary is the greatest. Or is she? She's beautiful she's not.\" He added, waving his shoulders when she finally spoke.\n",
      "\n",
      "\n",
      "Jupiter, who died in 1833, is one of the few of the Jupiter siblings that, if there is to be one, was born in one of his smaller cousins.'\n",
      "\n",
      "\n",
      "He added that his own niece: 'seemed very much suited to the duties with more humility. She'd like to go to college, would like to go back to the house of the Lord.'\n"
     ]
    }
   ],
   "source": [
    "def top_k_sampling(k):\n",
    "\n",
    "\n",
    "      def top_sampling(logits):\n",
    "          probs = t.nn.functional.softmax(logits)\n",
    "          values, indices = t.topk(probs, k)\n",
    "          index = values.multinomial(num_samples = 1, replacement = True)\n",
    "          return indices[index]\n",
    "      \n",
    "      return top_sampling\n",
    "\n",
    "# Initial model generates nonsense\n",
    "test_model(simpleGPT2, text = \"Mary is the greatest. Or is she?\", steps = 100, sampling = top_k_sampling(100))\n",
    "test_model(pretrained_model, text = \"Mary is the greatest. Or is she?\", is_hf = True, steps = 100, sampling = top_k_sampling(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fde2a27-c08a-4a3c-bfaa-deadcc89a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 0 0\n",
      "1 10 tensor(10.9798, device='cuda:0') tensor(6508, device='cuda:0')\n",
      "2 10 tensor(10.9784, device='cuda:0') tensor(12338, device='cuda:0')\n",
      "3 10 tensor(10.9790, device='cuda:0') tensor(18466, device='cuda:0')\n",
      "4 10 tensor(10.9789, device='cuda:0') tensor(24853, device='cuda:0')\n",
      "5 10 tensor(10.9767, device='cuda:0') tensor(30959, device='cuda:0')\n",
      "6 10 tensor(10.9785, device='cuda:0') tensor(37244, device='cuda:0')\n",
      "7 10 tensor(10.9808, device='cuda:0') tensor(43529, device='cuda:0')\n",
      "8 10 tensor(10.9815, device='cuda:0') tensor(50599, device='cuda:0')\n",
      "9 10 tensor(10.9811, device='cuda:0') tensor(57171, device='cuda:0')\n",
      "(tensor(10.9831, device='cuda:0'), tensor(63899, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(logits, encoded_input):\n",
    "    # logits: n x seq x d\n",
    "    # true_tokens: n x seq\n",
    "    # attention_mask = n x seq\n",
    "    true_tokens = encoded_input['input_ids']\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "    valid_samples_mask = attention_mask[:, 1:].reshape(-1).bool()\n",
    "    n, seq, d  = logits.shape\n",
    "    return t.nn.functional.cross_entropy(logits[:, :-1, :].reshape(-1, d)[valid_samples_mask, :], true_tokens[:, 1:].flatten()[valid_samples_mask]), valid_samples_mask.sum()\n",
    "\n",
    "def compute_dataset_loss(dataset, model, tokenizer):\n",
    "    loss = 0\n",
    "    samples = 0\n",
    "    with t.no_grad():\n",
    "      n = len(dataset)\n",
    "      batch_size = 10\n",
    "      batches = n // batch_size\n",
    "      for i in range(batches):\n",
    "          print(i, batch_size, loss, samples)\n",
    "          batch = dataset[i:i+batch_size]\n",
    "          encoded_input = tokenizer(batch, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "          logits = model(**encoded_input)\n",
    "          # Find true labels and compute loss\n",
    "          ce_loss, valid_samples = loss_fn(logits, encoded_input)\n",
    "          loss = (loss * samples + ce_loss * valid_samples ) / (samples + valid_samples)\n",
    "          samples = samples + valid_samples\n",
    "    return loss, samples\n",
    "\n",
    "# Compute loss of the pre-trained model on the truncated dataset\n",
    "print(compute_dataset_loss(dataset[:100], simpleGPT2, tokenizer))\n",
    "\n",
    "# Initial loss is ~11, remarkably high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de997d79-36e8-462f-84fb-742b2cd7c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_dataset_loss(dataset, model, tokenizer, val_frac = 0.2):\n",
    "    n = len(dataset)\n",
    "    val_size = int(n * val_frac)\n",
    "    return compute_dataset_loss(dataset[-val_size:], model, tokenizer)\n",
    "  \n",
    "# Compute validation loss\n",
    "# print(compute_val_dataset_loss(dataset, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "402e6ee2-d473-4426-b171-16598bea8e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "0 0.0 2 0 0\n",
      "10 0.01 2 tensor(6.1671, device='cuda:0', grad_fn=<DivBackward0>) tensor(10214, device='cuda:0')\n",
      "20 0.02 2 tensor(6.0966, device='cuda:0', grad_fn=<DivBackward0>) tensor(23063, device='cuda:0')\n",
      "30 0.03 2 tensor(6.2105, device='cuda:0', grad_fn=<DivBackward0>) tensor(33851, device='cuda:0')\n",
      "40 0.04 2 tensor(6.2714, device='cuda:0', grad_fn=<DivBackward0>) tensor(45368, device='cuda:0')\n",
      "50 0.05 2 tensor(6.2437, device='cuda:0', grad_fn=<DivBackward0>) tensor(57296, device='cuda:0')\n",
      "60 0.06 2 tensor(6.2237, device='cuda:0', grad_fn=<DivBackward0>) tensor(70440, device='cuda:0')\n",
      "70 0.07 2 tensor(6.2696, device='cuda:0', grad_fn=<DivBackward0>) tensor(80780, device='cuda:0')\n",
      "80 0.08 2 tensor(6.3039, device='cuda:0', grad_fn=<DivBackward0>) tensor(95638, device='cuda:0')\n",
      "90 0.09 2 tensor(6.3218, device='cuda:0', grad_fn=<DivBackward0>) tensor(104100, device='cuda:0')\n",
      "100 0.1 2 tensor(6.3069, device='cuda:0', grad_fn=<DivBackward0>) tensor(115847, device='cuda:0')\n",
      "110 0.11 2 tensor(6.3258, device='cuda:0', grad_fn=<DivBackward0>) tensor(130760, device='cuda:0')\n",
      "120 0.12 2 tensor(6.3243, device='cuda:0', grad_fn=<DivBackward0>) tensor(142222, device='cuda:0')\n",
      "130 0.13 2 tensor(6.3369, device='cuda:0', grad_fn=<DivBackward0>) tensor(155147, device='cuda:0')\n",
      "140 0.14 2 tensor(6.3271, device='cuda:0', grad_fn=<DivBackward0>) tensor(168346, device='cuda:0')\n",
      "150 0.15 2 tensor(6.3463, device='cuda:0', grad_fn=<DivBackward0>) tensor(182859, device='cuda:0')\n",
      "160 0.16 2 tensor(6.3765, device='cuda:0', grad_fn=<DivBackward0>) tensor(195541, device='cuda:0')\n",
      "170 0.17 2 tensor(6.3941, device='cuda:0', grad_fn=<DivBackward0>) tensor(208145, device='cuda:0')\n",
      "180 0.18 2 tensor(6.4005, device='cuda:0', grad_fn=<DivBackward0>) tensor(222478, device='cuda:0')\n",
      "190 0.19 2 tensor(6.4095, device='cuda:0', grad_fn=<DivBackward0>) tensor(237509, device='cuda:0')\n",
      "200 0.2 2 tensor(6.4043, device='cuda:0', grad_fn=<DivBackward0>) tensor(250700, device='cuda:0')\n",
      "210 0.21 2 tensor(6.3991, device='cuda:0', grad_fn=<DivBackward0>) tensor(259688, device='cuda:0')\n",
      "220 0.22 2 tensor(6.3913, device='cuda:0', grad_fn=<DivBackward0>) tensor(269991, device='cuda:0')\n",
      "230 0.23 2 tensor(6.3925, device='cuda:0', grad_fn=<DivBackward0>) tensor(281140, device='cuda:0')\n",
      "240 0.24 2 tensor(6.3855, device='cuda:0', grad_fn=<DivBackward0>) tensor(293608, device='cuda:0')\n",
      "250 0.25 2 tensor(6.3941, device='cuda:0', grad_fn=<DivBackward0>) tensor(306165, device='cuda:0')\n",
      "260 0.26 2 tensor(6.3925, device='cuda:0', grad_fn=<DivBackward0>) tensor(320261, device='cuda:0')\n",
      "270 0.27 2 tensor(6.3905, device='cuda:0', grad_fn=<DivBackward0>) tensor(332244, device='cuda:0')\n",
      "280 0.28 2 tensor(6.3937, device='cuda:0', grad_fn=<DivBackward0>) tensor(342827, device='cuda:0')\n",
      "290 0.29 2 tensor(6.3946, device='cuda:0', grad_fn=<DivBackward0>) tensor(354384, device='cuda:0')\n",
      "300 0.3 2 tensor(6.3891, device='cuda:0', grad_fn=<DivBackward0>) tensor(367427, device='cuda:0')\n",
      "310 0.31 2 tensor(6.4055, device='cuda:0', grad_fn=<DivBackward0>) tensor(379696, device='cuda:0')\n",
      "320 0.32 2 tensor(6.4059, device='cuda:0', grad_fn=<DivBackward0>) tensor(393888, device='cuda:0')\n",
      "330 0.33 2 tensor(6.4009, device='cuda:0', grad_fn=<DivBackward0>) tensor(407843, device='cuda:0')\n",
      "340 0.34 2 tensor(6.3906, device='cuda:0', grad_fn=<DivBackward0>) tensor(420566, device='cuda:0')\n",
      "350 0.35 2 tensor(6.3968, device='cuda:0', grad_fn=<DivBackward0>) tensor(434783, device='cuda:0')\n",
      "360 0.36 2 tensor(6.3980, device='cuda:0', grad_fn=<DivBackward0>) tensor(446800, device='cuda:0')\n",
      "370 0.37 2 tensor(6.3954, device='cuda:0', grad_fn=<DivBackward0>) tensor(458188, device='cuda:0')\n",
      "380 0.38 2 tensor(6.3938, device='cuda:0', grad_fn=<DivBackward0>) tensor(472259, device='cuda:0')\n",
      "390 0.39 2 tensor(6.3926, device='cuda:0', grad_fn=<DivBackward0>) tensor(482676, device='cuda:0')\n",
      "400 0.4 2 tensor(6.3887, device='cuda:0', grad_fn=<DivBackward0>) tensor(492515, device='cuda:0')\n",
      "410 0.41 2 tensor(6.3847, device='cuda:0', grad_fn=<DivBackward0>) tensor(503882, device='cuda:0')\n",
      "420 0.42 2 tensor(6.3911, device='cuda:0', grad_fn=<DivBackward0>) tensor(517092, device='cuda:0')\n",
      "430 0.43 2 tensor(6.3896, device='cuda:0', grad_fn=<DivBackward0>) tensor(527710, device='cuda:0')\n",
      "440 0.44 2 tensor(6.3928, device='cuda:0', grad_fn=<DivBackward0>) tensor(537664, device='cuda:0')\n",
      "450 0.45 2 tensor(6.3945, device='cuda:0', grad_fn=<DivBackward0>) tensor(552142, device='cuda:0')\n",
      "460 0.46 2 tensor(6.3978, device='cuda:0', grad_fn=<DivBackward0>) tensor(564903, device='cuda:0')\n",
      "470 0.47 2 tensor(6.3939, device='cuda:0', grad_fn=<DivBackward0>) tensor(578525, device='cuda:0')\n",
      "480 0.48 2 tensor(6.3987, device='cuda:0', grad_fn=<DivBackward0>) tensor(591084, device='cuda:0')\n",
      "490 0.49 2 tensor(6.3976, device='cuda:0', grad_fn=<DivBackward0>) tensor(602983, device='cuda:0')\n",
      "500 0.5 2 tensor(6.3934, device='cuda:0', grad_fn=<DivBackward0>) tensor(613298, device='cuda:0')\n",
      "510 0.51 2 tensor(6.3953, device='cuda:0', grad_fn=<DivBackward0>) tensor(623787, device='cuda:0')\n",
      "520 0.52 2 tensor(6.3949, device='cuda:0', grad_fn=<DivBackward0>) tensor(634003, device='cuda:0')\n",
      "530 0.53 2 tensor(6.3919, device='cuda:0', grad_fn=<DivBackward0>) tensor(645748, device='cuda:0')\n",
      "540 0.54 2 tensor(6.4008, device='cuda:0', grad_fn=<DivBackward0>) tensor(658743, device='cuda:0')\n",
      "550 0.55 2 tensor(6.3967, device='cuda:0', grad_fn=<DivBackward0>) tensor(671267, device='cuda:0')\n",
      "560 0.56 2 tensor(6.3957, device='cuda:0', grad_fn=<DivBackward0>) tensor(682247, device='cuda:0')\n",
      "570 0.57 2 tensor(6.3950, device='cuda:0', grad_fn=<DivBackward0>) tensor(690911, device='cuda:0')\n",
      "580 0.58 2 tensor(6.3923, device='cuda:0', grad_fn=<DivBackward0>) tensor(701791, device='cuda:0')\n",
      "590 0.59 2 tensor(6.3892, device='cuda:0', grad_fn=<DivBackward0>) tensor(716242, device='cuda:0')\n",
      "600 0.6 2 tensor(6.3886, device='cuda:0', grad_fn=<DivBackward0>) tensor(728984, device='cuda:0')\n",
      "610 0.61 2 tensor(6.3860, device='cuda:0', grad_fn=<DivBackward0>) tensor(739045, device='cuda:0')\n",
      "620 0.62 2 tensor(6.3861, device='cuda:0', grad_fn=<DivBackward0>) tensor(750603, device='cuda:0')\n",
      "630 0.63 2 tensor(6.3881, device='cuda:0', grad_fn=<DivBackward0>) tensor(761959, device='cuda:0')\n",
      "640 0.64 2 tensor(6.3881, device='cuda:0', grad_fn=<DivBackward0>) tensor(777253, device='cuda:0')\n",
      "650 0.65 2 tensor(6.3873, device='cuda:0', grad_fn=<DivBackward0>) tensor(787265, device='cuda:0')\n",
      "660 0.66 2 tensor(6.3863, device='cuda:0', grad_fn=<DivBackward0>) tensor(798211, device='cuda:0')\n",
      "670 0.67 2 tensor(6.3873, device='cuda:0', grad_fn=<DivBackward0>) tensor(811089, device='cuda:0')\n",
      "680 0.68 2 tensor(6.3870, device='cuda:0', grad_fn=<DivBackward0>) tensor(825167, device='cuda:0')\n",
      "690 0.69 2 tensor(6.3840, device='cuda:0', grad_fn=<DivBackward0>) tensor(835520, device='cuda:0')\n",
      "700 0.7 2 tensor(6.3811, device='cuda:0', grad_fn=<DivBackward0>) tensor(846452, device='cuda:0')\n",
      "710 0.71 2 tensor(6.3812, device='cuda:0', grad_fn=<DivBackward0>) tensor(856313, device='cuda:0')\n",
      "720 0.72 2 tensor(6.3811, device='cuda:0', grad_fn=<DivBackward0>) tensor(870697, device='cuda:0')\n",
      "730 0.73 2 tensor(6.3846, device='cuda:0', grad_fn=<DivBackward0>) tensor(880545, device='cuda:0')\n",
      "740 0.74 2 tensor(6.3858, device='cuda:0', grad_fn=<DivBackward0>) tensor(888930, device='cuda:0')\n",
      "750 0.75 2 tensor(6.3846, device='cuda:0', grad_fn=<DivBackward0>) tensor(902231, device='cuda:0')\n",
      "760 0.76 2 tensor(6.3884, device='cuda:0', grad_fn=<DivBackward0>) tensor(913192, device='cuda:0')\n",
      "770 0.77 2 tensor(6.3887, device='cuda:0', grad_fn=<DivBackward0>) tensor(926717, device='cuda:0')\n",
      "780 0.78 2 tensor(6.3890, device='cuda:0', grad_fn=<DivBackward0>) tensor(940132, device='cuda:0')\n",
      "790 0.79 2 tensor(6.3870, device='cuda:0', grad_fn=<DivBackward0>) tensor(951721, device='cuda:0')\n",
      "800 0.8 2 tensor(6.3887, device='cuda:0', grad_fn=<DivBackward0>) tensor(962233, device='cuda:0')\n",
      "810 0.81 2 tensor(6.3875, device='cuda:0', grad_fn=<DivBackward0>) tensor(975289, device='cuda:0')\n",
      "820 0.82 2 tensor(6.3858, device='cuda:0', grad_fn=<DivBackward0>) tensor(990041, device='cuda:0')\n",
      "830 0.83 2 tensor(6.3843, device='cuda:0', grad_fn=<DivBackward0>) tensor(1002502, device='cuda:0')\n",
      "840 0.84 2 tensor(6.3849, device='cuda:0', grad_fn=<DivBackward0>) tensor(1015574, device='cuda:0')\n",
      "850 0.85 2 tensor(6.3845, device='cuda:0', grad_fn=<DivBackward0>) tensor(1027774, device='cuda:0')\n",
      "860 0.86 2 tensor(6.3849, device='cuda:0', grad_fn=<DivBackward0>) tensor(1039937, device='cuda:0')\n",
      "870 0.87 2 tensor(6.3860, device='cuda:0', grad_fn=<DivBackward0>) tensor(1052308, device='cuda:0')\n",
      "880 0.88 2 tensor(6.3901, device='cuda:0', grad_fn=<DivBackward0>) tensor(1065220, device='cuda:0')\n",
      "890 0.89 2 tensor(6.3914, device='cuda:0', grad_fn=<DivBackward0>) tensor(1075589, device='cuda:0')\n",
      "900 0.9 2 tensor(6.3889, device='cuda:0', grad_fn=<DivBackward0>) tensor(1086768, device='cuda:0')\n",
      "910 0.91 2 tensor(6.3893, device='cuda:0', grad_fn=<DivBackward0>) tensor(1099317, device='cuda:0')\n",
      "920 0.92 2 tensor(6.3900, device='cuda:0', grad_fn=<DivBackward0>) tensor(1110176, device='cuda:0')\n",
      "930 0.93 2 tensor(6.3911, device='cuda:0', grad_fn=<DivBackward0>) tensor(1118453, device='cuda:0')\n",
      "940 0.94 2 tensor(6.3915, device='cuda:0', grad_fn=<DivBackward0>) tensor(1129369, device='cuda:0')\n",
      "950 0.95 2 tensor(6.3893, device='cuda:0', grad_fn=<DivBackward0>) tensor(1144452, device='cuda:0')\n",
      "960 0.96 2 tensor(6.3861, device='cuda:0', grad_fn=<DivBackward0>) tensor(1156466, device='cuda:0')\n",
      "970 0.97 2 tensor(6.3834, device='cuda:0', grad_fn=<DivBackward0>) tensor(1168486, device='cuda:0')\n",
      "980 0.98 2 tensor(6.3835, device='cuda:0', grad_fn=<DivBackward0>) tensor(1178748, device='cuda:0')\n",
      "990 0.99 2 tensor(6.3837, device='cuda:0', grad_fn=<DivBackward0>) tensor(1189676, device='cuda:0')\n",
      "(tensor(6.3835, device='cuda:0', grad_fn=<DivBackward0>), tensor(1203008, device='cuda:0'))\n",
      "Starting epoch:  0\n",
      "0 0.0 2 0 0\n",
      "10 0.01 2 tensor(5.9550, device='cuda:0', grad_fn=<DivBackward0>) tensor(13990, device='cuda:0')\n",
      "20 0.02 2 tensor(5.9849, device='cuda:0', grad_fn=<DivBackward0>) tensor(25845, device='cuda:0')\n",
      "30 0.03 2 tensor(6.1005, device='cuda:0', grad_fn=<DivBackward0>) tensor(40505, device='cuda:0')\n",
      "40 0.04 2 tensor(6.1788, device='cuda:0', grad_fn=<DivBackward0>) tensor(53592, device='cuda:0')\n",
      "50 0.05 2 tensor(6.1906, device='cuda:0', grad_fn=<DivBackward0>) tensor(66272, device='cuda:0')\n",
      "60 0.06 2 tensor(6.2033, device='cuda:0', grad_fn=<DivBackward0>) tensor(76914, device='cuda:0')\n",
      "70 0.07 2 tensor(6.2142, device='cuda:0', grad_fn=<DivBackward0>) tensor(88783, device='cuda:0')\n",
      "80 0.08 2 tensor(6.2245, device='cuda:0', grad_fn=<DivBackward0>) tensor(100476, device='cuda:0')\n",
      "90 0.09 2 tensor(6.2183, device='cuda:0', grad_fn=<DivBackward0>) tensor(113777, device='cuda:0')\n",
      "100 0.1 2 tensor(6.2669, device='cuda:0', grad_fn=<DivBackward0>) tensor(125206, device='cuda:0')\n",
      "110 0.11 2 tensor(6.2732, device='cuda:0', grad_fn=<DivBackward0>) tensor(139142, device='cuda:0')\n",
      "120 0.12 2 tensor(6.3387, device='cuda:0', grad_fn=<DivBackward0>) tensor(150631, device='cuda:0')\n",
      "130 0.13 2 tensor(6.3644, device='cuda:0', grad_fn=<DivBackward0>) tensor(166513, device='cuda:0')\n",
      "140 0.14 2 tensor(6.3624, device='cuda:0', grad_fn=<DivBackward0>) tensor(176964, device='cuda:0')\n",
      "150 0.15 2 tensor(6.3719, device='cuda:0', grad_fn=<DivBackward0>) tensor(187180, device='cuda:0')\n",
      "160 0.16 2 tensor(6.3807, device='cuda:0', grad_fn=<DivBackward0>) tensor(199135, device='cuda:0')\n",
      "170 0.17 2 tensor(6.3706, device='cuda:0', grad_fn=<DivBackward0>) tensor(209644, device='cuda:0')\n",
      "180 0.18 2 tensor(6.3604, device='cuda:0', grad_fn=<DivBackward0>) tensor(223372, device='cuda:0')\n",
      "190 0.19 2 tensor(6.3666, device='cuda:0', grad_fn=<DivBackward0>) tensor(238089, device='cuda:0')\n",
      "200 0.2 2 tensor(6.3624, device='cuda:0', grad_fn=<DivBackward0>) tensor(250210, device='cuda:0')\n",
      "210 0.21 2 tensor(6.3776, device='cuda:0', grad_fn=<DivBackward0>) tensor(264307, device='cuda:0')\n",
      "220 0.22 2 tensor(6.3788, device='cuda:0', grad_fn=<DivBackward0>) tensor(277270, device='cuda:0')\n",
      "230 0.23 2 tensor(6.3801, device='cuda:0', grad_fn=<DivBackward0>) tensor(289929, device='cuda:0')\n",
      "240 0.24 2 tensor(6.3636, device='cuda:0', grad_fn=<DivBackward0>) tensor(302526, device='cuda:0')\n",
      "250 0.25 2 tensor(6.3505, device='cuda:0', grad_fn=<DivBackward0>) tensor(313341, device='cuda:0')\n",
      "260 0.26 2 tensor(6.3574, device='cuda:0', grad_fn=<DivBackward0>) tensor(323824, device='cuda:0')\n",
      "270 0.27 2 tensor(6.3612, device='cuda:0', grad_fn=<DivBackward0>) tensor(336091, device='cuda:0')\n",
      "280 0.28 2 tensor(6.3562, device='cuda:0', grad_fn=<DivBackward0>) tensor(346031, device='cuda:0')\n",
      "290 0.29 2 tensor(6.3569, device='cuda:0', grad_fn=<DivBackward0>) tensor(357173, device='cuda:0')\n",
      "300 0.3 2 tensor(6.3486, device='cuda:0', grad_fn=<DivBackward0>) tensor(366964, device='cuda:0')\n",
      "310 0.31 2 tensor(6.3503, device='cuda:0', grad_fn=<DivBackward0>) tensor(378063, device='cuda:0')\n",
      "320 0.32 2 tensor(6.3578, device='cuda:0', grad_fn=<DivBackward0>) tensor(389878, device='cuda:0')\n",
      "330 0.33 2 tensor(6.3608, device='cuda:0', grad_fn=<DivBackward0>) tensor(405088, device='cuda:0')\n",
      "340 0.34 2 tensor(6.3652, device='cuda:0', grad_fn=<DivBackward0>) tensor(417201, device='cuda:0')\n",
      "350 0.35 2 tensor(6.3659, device='cuda:0', grad_fn=<DivBackward0>) tensor(427555, device='cuda:0')\n",
      "360 0.36 2 tensor(6.3676, device='cuda:0', grad_fn=<DivBackward0>) tensor(439027, device='cuda:0')\n",
      "370 0.37 2 tensor(6.3666, device='cuda:0', grad_fn=<DivBackward0>) tensor(449136, device='cuda:0')\n",
      "380 0.38 2 tensor(6.3659, device='cuda:0', grad_fn=<DivBackward0>) tensor(463355, device='cuda:0')\n",
      "390 0.39 2 tensor(6.3578, device='cuda:0', grad_fn=<DivBackward0>) tensor(478703, device='cuda:0')\n",
      "400 0.4 2 tensor(6.3543, device='cuda:0', grad_fn=<DivBackward0>) tensor(491431, device='cuda:0')\n",
      "410 0.41 2 tensor(6.3602, device='cuda:0', grad_fn=<DivBackward0>) tensor(506628, device='cuda:0')\n",
      "420 0.42 2 tensor(6.3566, device='cuda:0', grad_fn=<DivBackward0>) tensor(517480, device='cuda:0')\n",
      "430 0.43 2 tensor(6.3604, device='cuda:0', grad_fn=<DivBackward0>) tensor(530773, device='cuda:0')\n",
      "440 0.44 2 tensor(6.3654, device='cuda:0', grad_fn=<DivBackward0>) tensor(542554, device='cuda:0')\n",
      "450 0.45 2 tensor(6.3578, device='cuda:0', grad_fn=<DivBackward0>) tensor(554700, device='cuda:0')\n",
      "460 0.46 2 tensor(6.3622, device='cuda:0', grad_fn=<DivBackward0>) tensor(568043, device='cuda:0')\n",
      "470 0.47 2 tensor(6.3615, device='cuda:0', grad_fn=<DivBackward0>) tensor(577885, device='cuda:0')\n",
      "480 0.48 2 tensor(6.3629, device='cuda:0', grad_fn=<DivBackward0>) tensor(591985, device='cuda:0')\n",
      "490 0.49 2 tensor(6.3646, device='cuda:0', grad_fn=<DivBackward0>) tensor(603203, device='cuda:0')\n",
      "500 0.5 2 tensor(6.3694, device='cuda:0', grad_fn=<DivBackward0>) tensor(614745, device='cuda:0')\n",
      "510 0.51 2 tensor(6.3699, device='cuda:0', grad_fn=<DivBackward0>) tensor(628381, device='cuda:0')\n",
      "520 0.52 2 tensor(6.3697, device='cuda:0', grad_fn=<DivBackward0>) tensor(636609, device='cuda:0')\n",
      "530 0.53 2 tensor(6.3829, device='cuda:0', grad_fn=<DivBackward0>) tensor(650286, device='cuda:0')\n",
      "540 0.54 2 tensor(6.3829, device='cuda:0', grad_fn=<DivBackward0>) tensor(664079, device='cuda:0')\n",
      "550 0.55 2 tensor(6.3849, device='cuda:0', grad_fn=<DivBackward0>) tensor(675707, device='cuda:0')\n",
      "560 0.56 2 tensor(6.3890, device='cuda:0', grad_fn=<DivBackward0>) tensor(687096, device='cuda:0')\n",
      "570 0.57 2 tensor(6.3866, device='cuda:0', grad_fn=<DivBackward0>) tensor(699889, device='cuda:0')\n",
      "580 0.58 2 tensor(6.3888, device='cuda:0', grad_fn=<DivBackward0>) tensor(712801, device='cuda:0')\n",
      "590 0.59 2 tensor(6.3881, device='cuda:0', grad_fn=<DivBackward0>) tensor(724809, device='cuda:0')\n",
      "600 0.6 2 tensor(6.3857, device='cuda:0', grad_fn=<DivBackward0>) tensor(736738, device='cuda:0')\n",
      "610 0.61 2 tensor(6.3887, device='cuda:0', grad_fn=<DivBackward0>) tensor(748229, device='cuda:0')\n",
      "620 0.62 2 tensor(6.3874, device='cuda:0', grad_fn=<DivBackward0>) tensor(758588, device='cuda:0')\n",
      "630 0.63 2 tensor(6.3861, device='cuda:0', grad_fn=<DivBackward0>) tensor(771579, device='cuda:0')\n",
      "640 0.64 2 tensor(6.3857, device='cuda:0', grad_fn=<DivBackward0>) tensor(786314, device='cuda:0')\n",
      "650 0.65 2 tensor(6.3831, device='cuda:0', grad_fn=<DivBackward0>) tensor(796861, device='cuda:0')\n",
      "660 0.66 2 tensor(6.3847, device='cuda:0', grad_fn=<DivBackward0>) tensor(809190, device='cuda:0')\n",
      "670 0.67 2 tensor(6.3861, device='cuda:0', grad_fn=<DivBackward0>) tensor(821072, device='cuda:0')\n",
      "680 0.68 2 tensor(6.3871, device='cuda:0', grad_fn=<DivBackward0>) tensor(831449, device='cuda:0')\n",
      "690 0.69 2 tensor(6.3932, device='cuda:0', grad_fn=<DivBackward0>) tensor(845347, device='cuda:0')\n",
      "700 0.7 2 tensor(6.3990, device='cuda:0', grad_fn=<DivBackward0>) tensor(857978, device='cuda:0')\n",
      "710 0.71 2 tensor(6.3979, device='cuda:0', grad_fn=<DivBackward0>) tensor(870678, device='cuda:0')\n",
      "720 0.72 2 tensor(6.3938, device='cuda:0', grad_fn=<DivBackward0>) tensor(883281, device='cuda:0')\n",
      "730 0.73 2 tensor(6.3925, device='cuda:0', grad_fn=<DivBackward0>) tensor(896545, device='cuda:0')\n",
      "740 0.74 2 tensor(6.3910, device='cuda:0', grad_fn=<DivBackward0>) tensor(906642, device='cuda:0')\n",
      "750 0.75 2 tensor(6.3928, device='cuda:0', grad_fn=<DivBackward0>) tensor(919315, device='cuda:0')\n",
      "760 0.76 2 tensor(6.3898, device='cuda:0', grad_fn=<DivBackward0>) tensor(930990, device='cuda:0')\n",
      "770 0.77 2 tensor(6.3914, device='cuda:0', grad_fn=<DivBackward0>) tensor(947066, device='cuda:0')\n",
      "780 0.78 2 tensor(6.3903, device='cuda:0', grad_fn=<DivBackward0>) tensor(958459, device='cuda:0')\n",
      "790 0.79 2 tensor(6.3898, device='cuda:0', grad_fn=<DivBackward0>) tensor(970585, device='cuda:0')\n",
      "800 0.8 2 tensor(6.3900, device='cuda:0', grad_fn=<DivBackward0>) tensor(980086, device='cuda:0')\n",
      "810 0.81 2 tensor(6.3868, device='cuda:0', grad_fn=<DivBackward0>) tensor(990897, device='cuda:0')\n",
      "820 0.82 2 tensor(6.3887, device='cuda:0', grad_fn=<DivBackward0>) tensor(1003326, device='cuda:0')\n",
      "830 0.83 2 tensor(6.3910, device='cuda:0', grad_fn=<DivBackward0>) tensor(1015859, device='cuda:0')\n",
      "840 0.84 2 tensor(6.3889, device='cuda:0', grad_fn=<DivBackward0>) tensor(1029170, device='cuda:0')\n",
      "850 0.85 2 tensor(6.3883, device='cuda:0', grad_fn=<DivBackward0>) tensor(1040974, device='cuda:0')\n",
      "860 0.86 2 tensor(6.3879, device='cuda:0', grad_fn=<DivBackward0>) tensor(1053247, device='cuda:0')\n",
      "870 0.87 2 tensor(6.3883, device='cuda:0', grad_fn=<DivBackward0>) tensor(1066165, device='cuda:0')\n",
      "880 0.88 2 tensor(6.3867, device='cuda:0', grad_fn=<DivBackward0>) tensor(1077852, device='cuda:0')\n",
      "890 0.89 2 tensor(6.3916, device='cuda:0', grad_fn=<DivBackward0>) tensor(1091168, device='cuda:0')\n",
      "900 0.9 2 tensor(6.3941, device='cuda:0', grad_fn=<DivBackward0>) tensor(1104094, device='cuda:0')\n",
      "910 0.91 2 tensor(6.3921, device='cuda:0', grad_fn=<DivBackward0>) tensor(1113839, device='cuda:0')\n",
      "920 0.92 2 tensor(6.3940, device='cuda:0', grad_fn=<DivBackward0>) tensor(1128506, device='cuda:0')\n",
      "930 0.93 2 tensor(6.3923, device='cuda:0', grad_fn=<DivBackward0>) tensor(1139589, device='cuda:0')\n",
      "940 0.94 2 tensor(6.3997, device='cuda:0', grad_fn=<DivBackward0>) tensor(1152125, device='cuda:0')\n",
      "950 0.95 2 tensor(6.4005, device='cuda:0', grad_fn=<DivBackward0>) tensor(1163153, device='cuda:0')\n",
      "960 0.96 2 tensor(6.3980, device='cuda:0', grad_fn=<DivBackward0>) tensor(1176152, device='cuda:0')\n",
      "970 0.97 2 tensor(6.3968, device='cuda:0', grad_fn=<DivBackward0>) tensor(1188599, device='cuda:0')\n",
      "980 0.98 2 tensor(6.3974, device='cuda:0', grad_fn=<DivBackward0>) tensor(1204449, device='cuda:0')\n",
      "990 0.99 2 tensor(6.3977, device='cuda:0', grad_fn=<DivBackward0>) tensor(1215630, device='cuda:0')\n",
      "(tensor(6.3956, device='cuda:0', grad_fn=<DivBackward0>), tensor(1230803, device='cuda:0'))\n",
      "Starting epoch:  0\n",
      "0 0.0 2 0 0\n",
      "10 0.01 2 tensor(6.0148, device='cuda:0', grad_fn=<DivBackward0>) tensor(9968, device='cuda:0')\n",
      "20 0.02 2 tensor(6.1682, device='cuda:0', grad_fn=<DivBackward0>) tensor(23041, device='cuda:0')\n",
      "30 0.03 2 tensor(6.2157, device='cuda:0', grad_fn=<DivBackward0>) tensor(37247, device='cuda:0')\n",
      "40 0.04 2 tensor(6.2426, device='cuda:0', grad_fn=<DivBackward0>) tensor(49769, device='cuda:0')\n",
      "50 0.05 2 tensor(6.2134, device='cuda:0', grad_fn=<DivBackward0>) tensor(59976, device='cuda:0')\n",
      "60 0.06 2 tensor(6.2202, device='cuda:0', grad_fn=<DivBackward0>) tensor(73387, device='cuda:0')\n",
      "70 0.07 2 tensor(6.1974, device='cuda:0', grad_fn=<DivBackward0>) tensor(85205, device='cuda:0')\n",
      "80 0.08 2 tensor(6.2221, device='cuda:0', grad_fn=<DivBackward0>) tensor(99242, device='cuda:0')\n",
      "90 0.09 2 tensor(6.2364, device='cuda:0', grad_fn=<DivBackward0>) tensor(112078, device='cuda:0')\n",
      "100 0.1 2 tensor(6.2501, device='cuda:0', grad_fn=<DivBackward0>) tensor(126087, device='cuda:0')\n",
      "110 0.11 2 tensor(6.2337, device='cuda:0', grad_fn=<DivBackward0>) tensor(139353, device='cuda:0')\n",
      "120 0.12 2 tensor(6.2306, device='cuda:0', grad_fn=<DivBackward0>) tensor(152048, device='cuda:0')\n",
      "130 0.13 2 tensor(6.2359, device='cuda:0', grad_fn=<DivBackward0>) tensor(164628, device='cuda:0')\n",
      "140 0.14 2 tensor(6.2583, device='cuda:0', grad_fn=<DivBackward0>) tensor(177172, device='cuda:0')\n",
      "150 0.15 2 tensor(6.2509, device='cuda:0', grad_fn=<DivBackward0>) tensor(186427, device='cuda:0')\n",
      "160 0.16 2 tensor(6.2508, device='cuda:0', grad_fn=<DivBackward0>) tensor(197733, device='cuda:0')\n",
      "170 0.17 2 tensor(6.2529, device='cuda:0', grad_fn=<DivBackward0>) tensor(209949, device='cuda:0')\n",
      "180 0.18 2 tensor(6.2433, device='cuda:0', grad_fn=<DivBackward0>) tensor(222113, device='cuda:0')\n",
      "190 0.19 2 tensor(6.2461, device='cuda:0', grad_fn=<DivBackward0>) tensor(235174, device='cuda:0')\n",
      "200 0.2 2 tensor(6.2427, device='cuda:0', grad_fn=<DivBackward0>) tensor(249467, device='cuda:0')\n",
      "210 0.21 2 tensor(6.2582, device='cuda:0', grad_fn=<DivBackward0>) tensor(260188, device='cuda:0')\n",
      "220 0.22 2 tensor(6.2783, device='cuda:0', grad_fn=<DivBackward0>) tensor(273507, device='cuda:0')\n",
      "230 0.23 2 tensor(6.2921, device='cuda:0', grad_fn=<DivBackward0>) tensor(287623, device='cuda:0')\n",
      "240 0.24 2 tensor(6.2941, device='cuda:0', grad_fn=<DivBackward0>) tensor(299082, device='cuda:0')\n",
      "250 0.25 2 tensor(6.2951, device='cuda:0', grad_fn=<DivBackward0>) tensor(310243, device='cuda:0')\n",
      "260 0.26 2 tensor(6.2964, device='cuda:0', grad_fn=<DivBackward0>) tensor(321989, device='cuda:0')\n",
      "270 0.27 2 tensor(6.3077, device='cuda:0', grad_fn=<DivBackward0>) tensor(336346, device='cuda:0')\n",
      "280 0.28 2 tensor(6.3061, device='cuda:0', grad_fn=<DivBackward0>) tensor(348384, device='cuda:0')\n",
      "290 0.29 2 tensor(6.3078, device='cuda:0', grad_fn=<DivBackward0>) tensor(361895, device='cuda:0')\n",
      "300 0.3 2 tensor(6.3117, device='cuda:0', grad_fn=<DivBackward0>) tensor(375457, device='cuda:0')\n",
      "310 0.31 2 tensor(6.3067, device='cuda:0', grad_fn=<DivBackward0>) tensor(390009, device='cuda:0')\n",
      "320 0.32 2 tensor(6.3083, device='cuda:0', grad_fn=<DivBackward0>) tensor(401495, device='cuda:0')\n",
      "330 0.33 2 tensor(6.3035, device='cuda:0', grad_fn=<DivBackward0>) tensor(411868, device='cuda:0')\n",
      "340 0.34 2 tensor(6.3075, device='cuda:0', grad_fn=<DivBackward0>) tensor(421749, device='cuda:0')\n",
      "350 0.35 2 tensor(6.3135, device='cuda:0', grad_fn=<DivBackward0>) tensor(435583, device='cuda:0')\n",
      "360 0.36 2 tensor(6.3216, device='cuda:0', grad_fn=<DivBackward0>) tensor(445750, device='cuda:0')\n",
      "370 0.37 2 tensor(6.3181, device='cuda:0', grad_fn=<DivBackward0>) tensor(458889, device='cuda:0')\n",
      "380 0.38 2 tensor(6.3177, device='cuda:0', grad_fn=<DivBackward0>) tensor(470768, device='cuda:0')\n",
      "390 0.39 2 tensor(6.3174, device='cuda:0', grad_fn=<DivBackward0>) tensor(480675, device='cuda:0')\n",
      "400 0.4 2 tensor(6.3237, device='cuda:0', grad_fn=<DivBackward0>) tensor(493420, device='cuda:0')\n",
      "410 0.41 2 tensor(6.3291, device='cuda:0', grad_fn=<DivBackward0>) tensor(507663, device='cuda:0')\n",
      "420 0.42 2 tensor(6.3439, device='cuda:0', grad_fn=<DivBackward0>) tensor(520359, device='cuda:0')\n",
      "430 0.43 2 tensor(6.3464, device='cuda:0', grad_fn=<DivBackward0>) tensor(530585, device='cuda:0')\n",
      "440 0.44 2 tensor(6.3458, device='cuda:0', grad_fn=<DivBackward0>) tensor(540757, device='cuda:0')\n",
      "450 0.45 2 tensor(6.3412, device='cuda:0', grad_fn=<DivBackward0>) tensor(554493, device='cuda:0')\n",
      "460 0.46 2 tensor(6.3452, device='cuda:0', grad_fn=<DivBackward0>) tensor(566391, device='cuda:0')\n",
      "470 0.47 2 tensor(6.3501, device='cuda:0', grad_fn=<DivBackward0>) tensor(582560, device='cuda:0')\n",
      "480 0.48 2 tensor(6.3486, device='cuda:0', grad_fn=<DivBackward0>) tensor(595085, device='cuda:0')\n",
      "490 0.49 2 tensor(6.3498, device='cuda:0', grad_fn=<DivBackward0>) tensor(609773, device='cuda:0')\n",
      "500 0.5 2 tensor(6.3487, device='cuda:0', grad_fn=<DivBackward0>) tensor(621294, device='cuda:0')\n",
      "510 0.51 2 tensor(6.3680, device='cuda:0', grad_fn=<DivBackward0>) tensor(633882, device='cuda:0')\n",
      "520 0.52 2 tensor(6.3666, device='cuda:0', grad_fn=<DivBackward0>) tensor(645692, device='cuda:0')\n",
      "530 0.53 2 tensor(6.3690, device='cuda:0', grad_fn=<DivBackward0>) tensor(658361, device='cuda:0')\n",
      "540 0.54 2 tensor(6.3684, device='cuda:0', grad_fn=<DivBackward0>) tensor(668298, device='cuda:0')\n",
      "550 0.55 2 tensor(6.3706, device='cuda:0', grad_fn=<DivBackward0>) tensor(681586, device='cuda:0')\n",
      "560 0.56 2 tensor(6.3709, device='cuda:0', grad_fn=<DivBackward0>) tensor(692193, device='cuda:0')\n",
      "570 0.57 2 tensor(6.3716, device='cuda:0', grad_fn=<DivBackward0>) tensor(703557, device='cuda:0')\n",
      "580 0.58 2 tensor(6.3746, device='cuda:0', grad_fn=<DivBackward0>) tensor(714420, device='cuda:0')\n",
      "590 0.59 2 tensor(6.3783, device='cuda:0', grad_fn=<DivBackward0>) tensor(728598, device='cuda:0')\n",
      "600 0.6 2 tensor(6.3750, device='cuda:0', grad_fn=<DivBackward0>) tensor(740448, device='cuda:0')\n",
      "610 0.61 2 tensor(6.3734, device='cuda:0', grad_fn=<DivBackward0>) tensor(752803, device='cuda:0')\n",
      "620 0.62 2 tensor(6.3727, device='cuda:0', grad_fn=<DivBackward0>) tensor(764402, device='cuda:0')\n",
      "630 0.63 2 tensor(6.3692, device='cuda:0', grad_fn=<DivBackward0>) tensor(778204, device='cuda:0')\n",
      "640 0.64 2 tensor(6.3775, device='cuda:0', grad_fn=<DivBackward0>) tensor(788854, device='cuda:0')\n",
      "650 0.65 2 tensor(6.3766, device='cuda:0', grad_fn=<DivBackward0>) tensor(801710, device='cuda:0')\n",
      "660 0.66 2 tensor(6.3777, device='cuda:0', grad_fn=<DivBackward0>) tensor(813431, device='cuda:0')\n",
      "670 0.67 2 tensor(6.3785, device='cuda:0', grad_fn=<DivBackward0>) tensor(822692, device='cuda:0')\n",
      "680 0.68 2 tensor(6.3777, device='cuda:0', grad_fn=<DivBackward0>) tensor(835214, device='cuda:0')\n",
      "690 0.69 2 tensor(6.3738, device='cuda:0', grad_fn=<DivBackward0>) tensor(849051, device='cuda:0')\n",
      "700 0.7 2 tensor(6.3761, device='cuda:0', grad_fn=<DivBackward0>) tensor(862492, device='cuda:0')\n",
      "710 0.71 2 tensor(6.3765, device='cuda:0', grad_fn=<DivBackward0>) tensor(875821, device='cuda:0')\n",
      "720 0.72 2 tensor(6.3750, device='cuda:0', grad_fn=<DivBackward0>) tensor(887468, device='cuda:0')\n",
      "730 0.73 2 tensor(6.3747, device='cuda:0', grad_fn=<DivBackward0>) tensor(899350, device='cuda:0')\n",
      "740 0.74 2 tensor(6.3705, device='cuda:0', grad_fn=<DivBackward0>) tensor(912783, device='cuda:0')\n",
      "750 0.75 2 tensor(6.3698, device='cuda:0', grad_fn=<DivBackward0>) tensor(924566, device='cuda:0')\n",
      "760 0.76 2 tensor(6.3681, device='cuda:0', grad_fn=<DivBackward0>) tensor(934121, device='cuda:0')\n",
      "770 0.77 2 tensor(6.3694, device='cuda:0', grad_fn=<DivBackward0>) tensor(945921, device='cuda:0')\n",
      "780 0.78 2 tensor(6.3646, device='cuda:0', grad_fn=<DivBackward0>) tensor(959302, device='cuda:0')\n",
      "790 0.79 2 tensor(6.3642, device='cuda:0', grad_fn=<DivBackward0>) tensor(971749, device='cuda:0')\n",
      "800 0.8 2 tensor(6.3609, device='cuda:0', grad_fn=<DivBackward0>) tensor(983086, device='cuda:0')\n",
      "810 0.81 2 tensor(6.3592, device='cuda:0', grad_fn=<DivBackward0>) tensor(993879, device='cuda:0')\n",
      "820 0.82 2 tensor(6.3582, device='cuda:0', grad_fn=<DivBackward0>) tensor(1005643, device='cuda:0')\n",
      "830 0.83 2 tensor(6.3568, device='cuda:0', grad_fn=<DivBackward0>) tensor(1017862, device='cuda:0')\n",
      "840 0.84 2 tensor(6.3566, device='cuda:0', grad_fn=<DivBackward0>) tensor(1029236, device='cuda:0')\n",
      "850 0.85 2 tensor(6.3555, device='cuda:0', grad_fn=<DivBackward0>) tensor(1038270, device='cuda:0')\n",
      "860 0.86 2 tensor(6.3596, device='cuda:0', grad_fn=<DivBackward0>) tensor(1052098, device='cuda:0')\n",
      "870 0.87 2 tensor(6.3658, device='cuda:0', grad_fn=<DivBackward0>) tensor(1066107, device='cuda:0')\n",
      "880 0.88 2 tensor(6.3642, device='cuda:0', grad_fn=<DivBackward0>) tensor(1076947, device='cuda:0')\n",
      "890 0.89 2 tensor(6.3649, device='cuda:0', grad_fn=<DivBackward0>) tensor(1086425, device='cuda:0')\n",
      "900 0.9 2 tensor(6.3633, device='cuda:0', grad_fn=<DivBackward0>) tensor(1096847, device='cuda:0')\n",
      "910 0.91 2 tensor(6.3673, device='cuda:0', grad_fn=<DivBackward0>) tensor(1109059, device='cuda:0')\n",
      "920 0.92 2 tensor(6.3674, device='cuda:0', grad_fn=<DivBackward0>) tensor(1121685, device='cuda:0')\n",
      "930 0.93 2 tensor(6.3655, device='cuda:0', grad_fn=<DivBackward0>) tensor(1131261, device='cuda:0')\n",
      "940 0.94 2 tensor(6.3654, device='cuda:0', grad_fn=<DivBackward0>) tensor(1145293, device='cuda:0')\n",
      "950 0.95 2 tensor(6.3659, device='cuda:0', grad_fn=<DivBackward0>) tensor(1157225, device='cuda:0')\n",
      "960 0.96 2 tensor(6.3643, device='cuda:0', grad_fn=<DivBackward0>) tensor(1171945, device='cuda:0')\n",
      "970 0.97 2 tensor(6.3650, device='cuda:0', grad_fn=<DivBackward0>) tensor(1183902, device='cuda:0')\n",
      "980 0.98 2 tensor(6.3659, device='cuda:0', grad_fn=<DivBackward0>) tensor(1197842, device='cuda:0')\n",
      "990 0.99 2 tensor(6.3647, device='cuda:0', grad_fn=<DivBackward0>) tensor(1211833, device='cuda:0')\n",
      "(tensor(6.3621, device='cuda:0', grad_fn=<DivBackward0>), tensor(1223790, device='cuda:0'))\n",
      "Starting epoch:  0\n",
      "0 0.0 2 0 0\n",
      "10 0.01 2 tensor(6.6403, device='cuda:0', grad_fn=<DivBackward0>) tensor(13506, device='cuda:0')\n",
      "20 0.02 2 tensor(6.4044, device='cuda:0', grad_fn=<DivBackward0>) tensor(26669, device='cuda:0')\n",
      "30 0.03 2 tensor(6.4806, device='cuda:0', grad_fn=<DivBackward0>) tensor(37839, device='cuda:0')\n",
      "40 0.04 2 tensor(6.4454, device='cuda:0', grad_fn=<DivBackward0>) tensor(49476, device='cuda:0')\n",
      "50 0.05 2 tensor(6.3779, device='cuda:0', grad_fn=<DivBackward0>) tensor(59706, device='cuda:0')\n",
      "60 0.06 2 tensor(6.3605, device='cuda:0', grad_fn=<DivBackward0>) tensor(69157, device='cuda:0')\n",
      "70 0.07 2 tensor(6.3182, device='cuda:0', grad_fn=<DivBackward0>) tensor(80731, device='cuda:0')\n",
      "80 0.08 2 tensor(6.3101, device='cuda:0', grad_fn=<DivBackward0>) tensor(92869, device='cuda:0')\n",
      "90 0.09 2 tensor(6.2974, device='cuda:0', grad_fn=<DivBackward0>) tensor(105248, device='cuda:0')\n",
      "100 0.1 2 tensor(6.2663, device='cuda:0', grad_fn=<DivBackward0>) tensor(116483, device='cuda:0')\n",
      "110 0.11 2 tensor(6.2951, device='cuda:0', grad_fn=<DivBackward0>) tensor(129810, device='cuda:0')\n",
      "120 0.12 2 tensor(6.2872, device='cuda:0', grad_fn=<DivBackward0>) tensor(141166, device='cuda:0')\n",
      "130 0.13 2 tensor(6.2880, device='cuda:0', grad_fn=<DivBackward0>) tensor(156395, device='cuda:0')\n",
      "140 0.14 2 tensor(6.3006, device='cuda:0', grad_fn=<DivBackward0>) tensor(166868, device='cuda:0')\n",
      "150 0.15 2 tensor(6.3055, device='cuda:0', grad_fn=<DivBackward0>) tensor(180311, device='cuda:0')\n",
      "160 0.16 2 tensor(6.3025, device='cuda:0', grad_fn=<DivBackward0>) tensor(192304, device='cuda:0')\n",
      "170 0.17 2 tensor(6.2971, device='cuda:0', grad_fn=<DivBackward0>) tensor(204771, device='cuda:0')\n",
      "180 0.18 2 tensor(6.2906, device='cuda:0', grad_fn=<DivBackward0>) tensor(216677, device='cuda:0')\n",
      "190 0.19 2 tensor(6.2883, device='cuda:0', grad_fn=<DivBackward0>) tensor(229615, device='cuda:0')\n",
      "200 0.2 2 tensor(6.2787, device='cuda:0', grad_fn=<DivBackward0>) tensor(242715, device='cuda:0')\n",
      "210 0.21 2 tensor(6.2815, device='cuda:0', grad_fn=<DivBackward0>) tensor(256298, device='cuda:0')\n",
      "220 0.22 2 tensor(6.2753, device='cuda:0', grad_fn=<DivBackward0>) tensor(269798, device='cuda:0')\n",
      "230 0.23 2 tensor(6.2837, device='cuda:0', grad_fn=<DivBackward0>) tensor(282871, device='cuda:0')\n",
      "240 0.24 2 tensor(6.2781, device='cuda:0', grad_fn=<DivBackward0>) tensor(294891, device='cuda:0')\n",
      "250 0.25 2 tensor(6.2866, device='cuda:0', grad_fn=<DivBackward0>) tensor(308430, device='cuda:0')\n",
      "260 0.26 2 tensor(6.2926, device='cuda:0', grad_fn=<DivBackward0>) tensor(323052, device='cuda:0')\n",
      "270 0.27 2 tensor(6.2978, device='cuda:0', grad_fn=<DivBackward0>) tensor(336647, device='cuda:0')\n",
      "280 0.28 2 tensor(6.3062, device='cuda:0', grad_fn=<DivBackward0>) tensor(350152, device='cuda:0')\n",
      "290 0.29 2 tensor(6.3029, device='cuda:0', grad_fn=<DivBackward0>) tensor(361598, device='cuda:0')\n",
      "300 0.3 2 tensor(6.3001, device='cuda:0', grad_fn=<DivBackward0>) tensor(374079, device='cuda:0')\n",
      "310 0.31 2 tensor(6.3011, device='cuda:0', grad_fn=<DivBackward0>) tensor(386274, device='cuda:0')\n",
      "320 0.32 2 tensor(6.3023, device='cuda:0', grad_fn=<DivBackward0>) tensor(400703, device='cuda:0')\n",
      "330 0.33 2 tensor(6.2923, device='cuda:0', grad_fn=<DivBackward0>) tensor(411213, device='cuda:0')\n",
      "340 0.34 2 tensor(6.3011, device='cuda:0', grad_fn=<DivBackward0>) tensor(422735, device='cuda:0')\n",
      "350 0.35 2 tensor(6.2986, device='cuda:0', grad_fn=<DivBackward0>) tensor(434356, device='cuda:0')\n",
      "360 0.36 2 tensor(6.3023, device='cuda:0', grad_fn=<DivBackward0>) tensor(447714, device='cuda:0')\n",
      "370 0.37 2 tensor(6.3004, device='cuda:0', grad_fn=<DivBackward0>) tensor(459375, device='cuda:0')\n",
      "380 0.38 2 tensor(6.3072, device='cuda:0', grad_fn=<DivBackward0>) tensor(473380, device='cuda:0')\n",
      "390 0.39 2 tensor(6.3038, device='cuda:0', grad_fn=<DivBackward0>) tensor(486257, device='cuda:0')\n",
      "400 0.4 2 tensor(6.3026, device='cuda:0', grad_fn=<DivBackward0>) tensor(499464, device='cuda:0')\n",
      "410 0.41 2 tensor(6.3170, device='cuda:0', grad_fn=<DivBackward0>) tensor(514812, device='cuda:0')\n",
      "420 0.42 2 tensor(6.3168, device='cuda:0', grad_fn=<DivBackward0>) tensor(526986, device='cuda:0')\n",
      "430 0.43 2 tensor(6.3111, device='cuda:0', grad_fn=<DivBackward0>) tensor(539071, device='cuda:0')\n",
      "440 0.44 2 tensor(6.3184, device='cuda:0', grad_fn=<DivBackward0>) tensor(549883, device='cuda:0')\n",
      "450 0.45 2 tensor(6.3098, device='cuda:0', grad_fn=<DivBackward0>) tensor(562546, device='cuda:0')\n",
      "460 0.46 2 tensor(6.3024, device='cuda:0', grad_fn=<DivBackward0>) tensor(575328, device='cuda:0')\n",
      "470 0.47 2 tensor(6.3300, device='cuda:0', grad_fn=<DivBackward0>) tensor(588156, device='cuda:0')\n",
      "480 0.48 2 tensor(6.3334, device='cuda:0', grad_fn=<DivBackward0>) tensor(600262, device='cuda:0')\n",
      "490 0.49 2 tensor(6.3391, device='cuda:0', grad_fn=<DivBackward0>) tensor(615430, device='cuda:0')\n",
      "500 0.5 2 tensor(6.3394, device='cuda:0', grad_fn=<DivBackward0>) tensor(628106, device='cuda:0')\n",
      "510 0.51 2 tensor(6.3462, device='cuda:0', grad_fn=<DivBackward0>) tensor(640688, device='cuda:0')\n",
      "520 0.52 2 tensor(6.3491, device='cuda:0', grad_fn=<DivBackward0>) tensor(653080, device='cuda:0')\n",
      "530 0.53 2 tensor(6.3504, device='cuda:0', grad_fn=<DivBackward0>) tensor(662898, device='cuda:0')\n",
      "540 0.54 2 tensor(6.3554, device='cuda:0', grad_fn=<DivBackward0>) tensor(676085, device='cuda:0')\n",
      "550 0.55 2 tensor(6.3586, device='cuda:0', grad_fn=<DivBackward0>) tensor(686284, device='cuda:0')\n",
      "560 0.56 2 tensor(6.3606, device='cuda:0', grad_fn=<DivBackward0>) tensor(698239, device='cuda:0')\n",
      "570 0.57 2 tensor(6.3583, device='cuda:0', grad_fn=<DivBackward0>) tensor(709321, device='cuda:0')\n",
      "580 0.58 2 tensor(6.3636, device='cuda:0', grad_fn=<DivBackward0>) tensor(721465, device='cuda:0')\n",
      "590 0.59 2 tensor(6.3634, device='cuda:0', grad_fn=<DivBackward0>) tensor(734628, device='cuda:0')\n",
      "600 0.6 2 tensor(6.3620, device='cuda:0', grad_fn=<DivBackward0>) tensor(748819, device='cuda:0')\n",
      "610 0.61 2 tensor(6.3668, device='cuda:0', grad_fn=<DivBackward0>) tensor(760242, device='cuda:0')\n",
      "620 0.62 2 tensor(6.3630, device='cuda:0', grad_fn=<DivBackward0>) tensor(772355, device='cuda:0')\n",
      "630 0.63 2 tensor(6.3676, device='cuda:0', grad_fn=<DivBackward0>) tensor(783129, device='cuda:0')\n",
      "640 0.64 2 tensor(6.3685, device='cuda:0', grad_fn=<DivBackward0>) tensor(790747, device='cuda:0')\n",
      "650 0.65 2 tensor(6.3754, device='cuda:0', grad_fn=<DivBackward0>) tensor(804356, device='cuda:0')\n",
      "660 0.66 2 tensor(6.3759, device='cuda:0', grad_fn=<DivBackward0>) tensor(817532, device='cuda:0')\n",
      "670 0.67 2 tensor(6.3800, device='cuda:0', grad_fn=<DivBackward0>) tensor(828187, device='cuda:0')\n",
      "680 0.68 2 tensor(6.3805, device='cuda:0', grad_fn=<DivBackward0>) tensor(842582, device='cuda:0')\n",
      "690 0.69 2 tensor(6.3784, device='cuda:0', grad_fn=<DivBackward0>) tensor(854080, device='cuda:0')\n",
      "700 0.7 2 tensor(6.3856, device='cuda:0', grad_fn=<DivBackward0>) tensor(867614, device='cuda:0')\n",
      "710 0.71 2 tensor(6.3874, device='cuda:0', grad_fn=<DivBackward0>) tensor(879187, device='cuda:0')\n",
      "720 0.72 2 tensor(6.3888, device='cuda:0', grad_fn=<DivBackward0>) tensor(891037, device='cuda:0')\n",
      "730 0.73 2 tensor(6.3864, device='cuda:0', grad_fn=<DivBackward0>) tensor(902681, device='cuda:0')\n",
      "740 0.74 2 tensor(6.3873, device='cuda:0', grad_fn=<DivBackward0>) tensor(914332, device='cuda:0')\n",
      "750 0.75 2 tensor(6.3866, device='cuda:0', grad_fn=<DivBackward0>) tensor(925833, device='cuda:0')\n",
      "760 0.76 2 tensor(6.3849, device='cuda:0', grad_fn=<DivBackward0>) tensor(936661, device='cuda:0')\n",
      "770 0.77 2 tensor(6.3846, device='cuda:0', grad_fn=<DivBackward0>) tensor(949538, device='cuda:0')\n",
      "780 0.78 2 tensor(6.3869, device='cuda:0', grad_fn=<DivBackward0>) tensor(959846, device='cuda:0')\n",
      "790 0.79 2 tensor(6.3842, device='cuda:0', grad_fn=<DivBackward0>) tensor(972916, device='cuda:0')\n",
      "800 0.8 2 tensor(6.3868, device='cuda:0', grad_fn=<DivBackward0>) tensor(983002, device='cuda:0')\n",
      "810 0.81 2 tensor(6.3904, device='cuda:0', grad_fn=<DivBackward0>) tensor(993930, device='cuda:0')\n",
      "820 0.82 2 tensor(6.3885, device='cuda:0', grad_fn=<DivBackward0>) tensor(1007981, device='cuda:0')\n",
      "830 0.83 2 tensor(6.3863, device='cuda:0', grad_fn=<DivBackward0>) tensor(1019514, device='cuda:0')\n",
      "840 0.84 2 tensor(6.3861, device='cuda:0', grad_fn=<DivBackward0>) tensor(1031779, device='cuda:0')\n",
      "850 0.85 2 tensor(6.3916, device='cuda:0', grad_fn=<DivBackward0>) tensor(1045227, device='cuda:0')\n",
      "860 0.86 2 tensor(6.3992, device='cuda:0', grad_fn=<DivBackward0>) tensor(1057367, device='cuda:0')\n",
      "870 0.87 2 tensor(6.3928, device='cuda:0', grad_fn=<DivBackward0>) tensor(1071953, device='cuda:0')\n",
      "880 0.88 2 tensor(6.3917, device='cuda:0', grad_fn=<DivBackward0>) tensor(1081808, device='cuda:0')\n",
      "890 0.89 2 tensor(6.3908, device='cuda:0', grad_fn=<DivBackward0>) tensor(1092403, device='cuda:0')\n",
      "900 0.9 2 tensor(6.3907, device='cuda:0', grad_fn=<DivBackward0>) tensor(1104124, device='cuda:0')\n",
      "910 0.91 2 tensor(6.3875, device='cuda:0', grad_fn=<DivBackward0>) tensor(1118374, device='cuda:0')\n",
      "920 0.92 2 tensor(6.3875, device='cuda:0', grad_fn=<DivBackward0>) tensor(1132079, device='cuda:0')\n",
      "930 0.93 2 tensor(6.3877, device='cuda:0', grad_fn=<DivBackward0>) tensor(1144956, device='cuda:0')\n",
      "940 0.94 2 tensor(6.3917, device='cuda:0', grad_fn=<DivBackward0>) tensor(1160958, device='cuda:0')\n",
      "950 0.95 2 tensor(6.3911, device='cuda:0', grad_fn=<DivBackward0>) tensor(1174132, device='cuda:0')\n",
      "960 0.96 2 tensor(6.3908, device='cuda:0', grad_fn=<DivBackward0>) tensor(1184969, device='cuda:0')\n",
      "970 0.97 2 tensor(6.3905, device='cuda:0', grad_fn=<DivBackward0>) tensor(1195964, device='cuda:0')\n",
      "980 0.98 2 tensor(6.3881, device='cuda:0', grad_fn=<DivBackward0>) tensor(1208785, device='cuda:0')\n",
      "990 0.99 2 tensor(6.3890, device='cuda:0', grad_fn=<DivBackward0>) tensor(1220923, device='cuda:0')\n",
      "(tensor(6.3886, device='cuda:0', grad_fn=<DivBackward0>), tensor(1231895, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model on a subset of training set, and then evaluate on val set\n",
    "import random\n",
    "\n",
    "def train_model(dataset, optimizer, epochs, model, tokenizer):\n",
    "    loss = 0\n",
    "    samples = 0\n",
    "    n = len(dataset)\n",
    "    batch_size = 2\n",
    "    batches = n // batch_size\n",
    "    print_interval = batches // 100\n",
    "\n",
    "    scheduler = OneCycleLR(optimizer, max_lr = 2.5e-4, total_steps = epochs * batches, pct_start = 0.2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Starting epoch: \", epoch)\n",
    "        for i in range(batches):\n",
    "            if i % print_interval == 0:\n",
    "                print(i, i/float(batches), batch_size, loss, samples)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch = dataset[i:i+batch_size]\n",
    "            for i, e in enumerate(batch):\n",
    "                offset = random.randint(0, max(len(e) - 2048, 0))\n",
    "                batch[i] = e[offset:]\n",
    "            encoded_input = tokenizer(batch, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "            logits = model(**encoded_input)\n",
    "\n",
    "            # Find true labels and compute loss\n",
    "            ce_loss, valid_samples = loss_fn(logits, encoded_input)\n",
    "            loss = (loss * samples + ce_loss * valid_samples ) / (samples + valid_samples)\n",
    "            samples = samples + valid_samples\n",
    "\n",
    "            # Backprop\n",
    "            ce_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "    return loss, samples\n",
    "\n",
    "epochs = 1\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import random\n",
    "\n",
    "lrs = [5e-5, 5e-4, 1e-5, 2e-5]\n",
    "\n",
    "for i in range(4):\n",
    "  start_idx = 2000*i\n",
    "  end_idx = 2000*(i+1)\n",
    "  optimizer = Adam(simpleGPT2.parameters(), lr = lrs[-1])\n",
    "  print(train_model(dataset[start_idx:end_idx], optimizer, epochs, simpleGPT2, tokenizer))\n",
    "# Loss reaches 6.3 after 3 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e57a0e7-f47b-4f17-a8be-dde9a12f4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt: Mary is the greatest. Or is she?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-cd70a51e302d>:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = t.nn.functional.softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current generation: Mary is the greatest. Or is she? These. In an game that's so for an project. And maybe, a reason to say,� and it could be written that the time he was the last issue that is possible if if the Nationaly, for more expensive. The early is.\n",
      "\n",
      " not if it is no longer is able to try, from the two weeks. The most than an end of any reason that at Tuesday. �ed at it should be possible was there should probably really if you can.\n",
      "\n",
      ".\n",
      "Starting prompt: Mary is the greatest. Or is she?\n",
      "Current generation: Mary is the greatest. Or is she?\n",
      "\n",
      "\n",
      "\"Come now,\" he said to Lydia with his back to him. \"Will you be glad to forgive Peter here?\"\n",
      "\n",
      "\n",
      "Lydia nodded. \"I think more than done, and we would like to see him, if we can, for many an occasion,\" he added.\n",
      "\n",
      "\n",
      "\"With great regret,\" she replied. \"All was very well, though we had never been at any table together for many years; but one night we were all on our knees looking\n",
      "0 10 0 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.92 GiB (GPU 0; 22.06 GiB total capacity; 18.22 GiB already allocated; 1.14 GiB free; 19.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-72152ae10215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimpleGPT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Mary is the greatest. Or is she?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_k_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Mary is the greatest. Or is she?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_hf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_k_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_val_dataset_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimpleGPT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-95f421039d3b>\u001b[0m in \u001b[0;36mcompute_val_dataset_loss\u001b[0;34m(dataset, model, tokenizer, val_frac)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval_frac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_dataset_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mval_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Compute validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a6def445b98f>\u001b[0m in \u001b[0;36mcompute_dataset_loss\u001b[0;34m(dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0;31m# Find true labels and compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mce_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalid_samples\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalid_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalid_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a6def445b98f>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(logits, encoded_input)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_samples_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_samples_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_samples_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_samples_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_dataset_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.92 GiB (GPU 0; 22.06 GiB total capacity; 18.22 GiB already allocated; 1.14 GiB free; 19.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "test_model(simpleGPT2, text = \"Mary is the greatest. Or is she?\", steps = 100, sampling = top_k_sampling(100))\n",
    "test_model(pretrained_model, text = \"Mary is the greatest. Or is she?\", is_hf = True, steps = 100, sampling = top_k_sampling(100))\n",
    "print(compute_val_dataset_loss(dataset, simpleGPT2, tokenizer, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5090d7-b32c-4fad-8f31-55bbe60558b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
